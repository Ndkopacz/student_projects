{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i7JvTKJ5dbld"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "  # %tensorflow_version only exists in Colab.\n",
    "  %tensorflow_version 2.x\n",
    "except Exception:\n",
    "  pass\n",
    "import tensorflow as tf\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "# List all physical devices recognized by TensorFlow\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "print(\"Available GPUs:\", physical_devices)\n",
    "if gpus :\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        tf.config.experimental.set_virtual_device_configuration(gpus[0],[tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1024 * 4)])\n",
    "\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ER819eogVBeh"
   },
   "source": [
    "# **Uploading file from your directory**\n",
    " The file you upload should be a zip folder containing your dataset.\n",
    "This code below will prompt you to select and upload the zip file from your local computer into colab directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q36d4ovafwfH"
   },
   "outputs": [],
   "source": [
    "#comment out cell if using a local machine\n",
    "\n",
    "from google.colab import files\n",
    "uploaded = files.upload()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mhm7rVCPVPeT"
   },
   "source": [
    "# **Unziping the Folder in Colab**\n",
    "Here you should be able to see the extracted zip folder in your colab folder directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZFl0Qmn4doIN"
   },
   "outputs": [],
   "source": [
    "#comment out cell if using a local machine\n",
    "\n",
    "import zipfile\n",
    "\n",
    "for filename in uploaded.keys():\n",
    "    if filename.endswith('.zip'):\n",
    "        zip_ref = zipfile.ZipFile(filename, 'r')\n",
    "        zip_ref.extractall()\n",
    "        print(f\"Extracted folder correctly {filename}\")\n",
    "        zip_ref.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "05CN5N_DLPvx"
   },
   "source": [
    "# **Import Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7kzadsFWVZp5"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import random\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "elZ4-eUcdbld"
   },
   "source": [
    "##  **Preparing and getting the file directories**\n",
    "Here we are getting the folder directories for the Car and Bike folder which is found in the parent folder called Car-Bike-Dataset which we have already extracted above from our zip folder if we used Colab environment. With your local machine it should open the current directory where your dataset is located and point to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2GJmB16Adbld"
   },
   "outputs": [],
   "source": [
    "# if using local machine, ensure that the zip file has been unzipped in the same\n",
    "#folder as the one which has this notebook\n",
    "\n",
    "# Get the current directory\n",
    "current_dir = os.getcwd()\n",
    "print(\"Current directory:\", current_dir)\n",
    "\n",
    "# Set the correct target folder path\n",
    "target_folder = os.path.join(current_dir, \"Car-Bike-Dataset\")\n",
    "print(\"Target folder path:\", target_folder)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xnr97Sp6LCQ2"
   },
   "source": [
    "## Getting the path for the training and test images for the Car and bike"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xreIvkxfLCQ2"
   },
   "outputs": [],
   "source": [
    "# Define the actual train and test paths for both Car and Bike\n",
    "car_train_folder = os.path.join(target_folder, \"Car\", \"train_images\")\n",
    "car_test_folder = os.path.join(target_folder, \"Car\", \"test_images\")\n",
    "bike_train_folder = os.path.join(target_folder, \"Bike\", \"train_images\")\n",
    "bike_test_folder = os.path.join(target_folder, \"Bike\", \"test_images\")\n",
    "\n",
    "print(\"Car train data path:\", car_train_folder)\n",
    "print(\"Car test data path:\", car_test_folder)\n",
    "print(\"Bike train data path:\", bike_train_folder)\n",
    "print(\"Bike test data path:\", bike_test_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LH-BcVraLCQ2"
   },
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 150"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XuX5PgLHVwCm"
   },
   "source": [
    "# Getting and loading the dataset\n",
    "Here, this function below will help us load the dataset we obatined above for the car_folder and bike_folder respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4q0X8lXUdbld"
   },
   "outputs": [],
   "source": [
    "# Function to load dataset\n",
    "def load_dataset(folder, label):\n",
    "    data = []\n",
    "    labels = []\n",
    "    for filename in os.listdir(folder):\n",
    "        img_path = os.path.join(folder, filename)\n",
    "        try:\n",
    "            image = load_img(img_path, target_size=(IMAGE_SIZE, IMAGE_SIZE))\n",
    "            image = img_to_array(image) / 255.0\n",
    "            data.append(image)\n",
    "            labels.append(label)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {img_path}: {e}\")\n",
    "\n",
    "    return np.array(data), np.array(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BMYMkCFYLCQ3"
   },
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AZg4D8_Ddbld"
   },
   "outputs": [],
   "source": [
    "# Load training data\n",
    "train_images_car, train_labels_car = load_dataset(car_train_folder, 1)\n",
    "train_images_bike, train_labels_bike = load_dataset(bike_train_folder, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j7ZobgzWLCQ3"
   },
   "outputs": [],
   "source": [
    "# Load testing data\n",
    "test_images_car, test_labels_car = load_dataset(car_test_folder, 1)\n",
    "test_images_bike, test_labels_bike = load_dataset(bike_test_folder, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X1ij7mSNLCQ3"
   },
   "outputs": [],
   "source": [
    "# Combine training data\n",
    "train_images = np.concatenate([train_images_car, train_images_bike])\n",
    "train_labels = np.concatenate([train_labels_car, train_labels_bike])\n",
    "\n",
    "# Combine testing data\n",
    "test_images = np.concatenate([test_images_car, test_images_bike])\n",
    "test_labels = np.concatenate([test_labels_car, test_labels_bike])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nvWtKlOTLCQ3"
   },
   "source": [
    "## Check the number of images loaded for training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kRfL1uFDLCQ3"
   },
   "outputs": [],
   "source": [
    "print(f\"Number of training images: {len(train_images)}\")\n",
    "print(f\"Number of test images: {len(test_images)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LjH8rgbULCQ3"
   },
   "source": [
    "## Displaying sample images for Car and Bike"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lOKLbJEYLCQ3"
   },
   "outputs": [],
   "source": [
    "# Function to plot 5 sample images\n",
    "def plot_sample_images(images, labels, num_samples=10, images_per_row=5):\n",
    "    num_rows = (num_samples + images_per_row - 1) // images_per_row\n",
    "    plt.figure(figsize=(images_per_row * 3, num_rows * 3))\n",
    "\n",
    "    indices = random.sample(range(len(images)), num_samples)\n",
    "\n",
    "    for i, index in enumerate(indices):\n",
    "        plt.subplot(num_rows, images_per_row, i + 1)\n",
    "        plt.imshow(images[index])\n",
    "        label = 'Car' if labels[index] == 1 else 'Bike'\n",
    "        plt.title(label)\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plot 10 sample images (5 images per row)\n",
    "plot_sample_images(train_images, train_labels, num_samples=10, images_per_row=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nmZQD9blLCQ4"
   },
   "source": [
    "<!-- ## Split the data into train and test sets\n",
    "To help our model learn correctly we are splitting the dataset into 90% training and 10% testing -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UzHKNYjrLCQ4"
   },
   "source": [
    "# Define your model for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uc4pW9UkLCQ4"
   },
   "outputs": [],
   "source": [
    "#Build your model\n",
    "model = tf.keras.models.Sequential([\n",
    "   #Insert your model here\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w48s2eXBYKUF"
   },
   "source": [
    "# Compiling the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CCdUNf2qLCQ4"
   },
   "outputs": [],
   "source": [
    "#Feel free to update optimizer\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_I1pNoxgLCQ4"
   },
   "source": [
    "##  Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xtv2uDBtLCQ4"
   },
   "outputs": [],
   "source": [
    "#Feel free to update hyperparameters\n",
    "\n",
    "history = model.fit(\n",
    "    train_images, train_labels,\n",
    "    epochs=20,\n",
    "    batch_size=32,\n",
    "    validation_split=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IaWlYFSRLCQ4"
   },
   "source": [
    "## Evaluating the model\n",
    "Here we evaluate the model on the test set to see the final accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TDtvFJozLCQ5"
   },
   "outputs": [],
   "source": [
    "# Evaluate the model on the test set (validation set)\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(test_images, test_labels, verbose=2)\n",
    "print(f\"Test Set Accuracy: {test_accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LxMsny6HLCQ5"
   },
   "source": [
    "## Visualization of Training and Validation Loss and Accuracy\n",
    "The plots provide a visual representation of the model's training process over multiple epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wcfd-HB3LCQ5"
   },
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Plot training & validation accuracy values\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MhEVyZ7BLCQ5"
   },
   "source": [
    "## Getting to see the predicted images for both car and bike\n",
    "Here, based on how well the model was able to train you will be able to see if predicting 90% accurately from the test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XvVMXZp2LCQ5",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Function to predict and visualize multiple images from the test set\n",
    "def predict_and_visualize_multiple(model, test_images, test_labels, num_samples=10, images_per_row=5):\n",
    "    num_rows = (num_samples + images_per_row - 1) // images_per_row\n",
    "    plt.figure(figsize=(images_per_row * 3, num_rows * 3))\n",
    "\n",
    "    # Randomly sample indices from the test set\n",
    "    indices = random.sample(range(len(test_images)), num_samples)\n",
    "\n",
    "    for i, index in enumerate(indices):\n",
    "        plt.subplot(num_rows, images_per_row, i + 1)\n",
    "        img = test_images[index]\n",
    "        true_label = 'Car' if test_labels[index] == 1 else 'Bike'\n",
    "\n",
    "        # Expand the dimensions for model prediction\n",
    "        img_array = np.expand_dims(img, axis=0)\n",
    "\n",
    "        # Predict the label\n",
    "        prediction = model.predict(img_array)\n",
    "        predicted_label = 'Car' if prediction[0][0] > 0.5 else 'Bike'\n",
    "        probability = prediction[0][0]\n",
    "\n",
    "        # Display the image and the prediction\n",
    "        plt.imshow(img)\n",
    "        plt.title(f\"True: {true_label}\\nPred: {predicted_label} ({probability:.2f})\")\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Call the function to predict and visualize 10 random images from the test set\n",
    "predict_and_visualize_multiple(model, test_images, test_labels, num_samples=10, images_per_row=5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "amRmRdcoLCQ5"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "anaconda-cloud": {},
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
