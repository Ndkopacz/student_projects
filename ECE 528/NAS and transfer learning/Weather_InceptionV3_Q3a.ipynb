{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade keras tensorflow\n"
      ],
      "metadata": {
        "id": "zSNuSJgjF9lg"
      },
      "id": "zSNuSJgjF9lg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5ee26e0e-61fa-4f57-b8fe-e07176d9dfc1",
      "metadata": {
        "id": "5ee26e0e-61fa-4f57-b8fe-e07176d9dfc1"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.inception_v3 import preprocess_input\n",
        "\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "effabffa-d8de-46d4-99c4-0c7a90bf9178",
      "metadata": {
        "id": "effabffa-d8de-46d4-99c4-0c7a90bf9178"
      },
      "source": [
        "# **Uploading file from your direcorty**\n",
        " The file you upload should be a zip folder containing your dataset.\n",
        "This code below will prompt you to select and upload the zip file from your local computer into colab directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6165c0ce-b496-4532-a655-1fdf951171ed",
      "metadata": {
        "id": "6165c0ce-b496-4532-a655-1fdf951171ed"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "50669da2-f589-4569-a004-0d51b94df258",
      "metadata": {
        "id": "50669da2-f589-4569-a004-0d51b94df258"
      },
      "source": [
        "# **Unziping the Folder in Colab**\n",
        "Here you should be able to see the extracted zip folder in your colab folder directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5970d173-4e40-4e4b-aaec-5b95ec260d1f",
      "metadata": {
        "id": "5970d173-4e40-4e4b-aaec-5b95ec260d1f"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "\n",
        "for filename in uploaded.keys():\n",
        "    if filename.endswith('.zip'):\n",
        "        zip_ref = zipfile.ZipFile(filename, 'r')\n",
        "        zip_ref.extractall()\n",
        "        print(f\"Extracted folder correctly {filename}\")\n",
        "        zip_ref.close()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "013a08ea-7aa1-43d3-8099-e967867efdf3",
      "metadata": {
        "id": "013a08ea-7aa1-43d3-8099-e967867efdf3"
      },
      "source": [
        "## Data download"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fe436503-1aa1-4f12-ba5d-43a6a864ccb7",
      "metadata": {
        "id": "fe436503-1aa1-4f12-ba5d-43a6a864ccb7"
      },
      "outputs": [],
      "source": [
        "# Define paths for the weather condition folders\n",
        "weather_conditions = ['rain', 'hail', 'glaze', 'frost', 'fogsmog', 'dew',\n",
        "                      'lightning', 'rainbow', 'rime', 'sandstorm', 'snow']\n",
        "print(weather_conditions)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "27950710-c0f3-462b-a90d-677e9cf6ce39",
      "metadata": {
        "id": "27950710-c0f3-462b-a90d-677e9cf6ce39"
      },
      "source": [
        "##  Preparing and getting the file directories\n",
        "Here we are getting the folder directories for the various Weather Condition folder which is found in the parent folder called WeatherDataset which we have already extracted above from our zip folder if we used Colab environment. With your local machine it should open the current directory where your dataset is located and point to it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ebc2bfeb-6b33-4674-ab2e-689ce855caa9",
      "metadata": {
        "id": "ebc2bfeb-6b33-4674-ab2e-689ce855caa9"
      },
      "outputs": [],
      "source": [
        "# Get parent directory\n",
        "parent_dir = os.getcwd()\n",
        "print(parent_dir)\n",
        "\n",
        "# List the extracted contents in your Colab ennvironment to see where the extracted folder is found at and point it to the correct path below\n",
        "extracted_files = os.listdir(parent_dir)\n",
        "\n",
        "\n",
        "# find the 'WeatherDataset' folder extracted in your colab directory\n",
        "weather_dataset_folder = 'WeatherDataset'\n",
        "if weather_dataset_folder not in extracted_files:\n",
        "    raise FileNotFoundError(f\"'{weather_dataset_folder}' folder not found in {parent_dir}\")\n",
        "\n",
        "weather_dataset_path = os.path.join(parent_dir, weather_dataset_folder)\n",
        "print(f\"WeatherDataset folder path: {weather_dataset_path}\")\n",
        "\n",
        "\n",
        "# # # # Define train and test folders\n",
        "train_folders = [os.path.join(weather_dataset_path, condition, 'train') for condition in weather_conditions]\n",
        "test_folders = [os.path.join(weather_dataset_path, condition, 'test') for condition in weather_conditions]\n",
        "print(train_folders)\n",
        "print(test_folders)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f759f8f6-6f2b-4211-b94c-4aaece20eb03",
      "metadata": {
        "id": "f759f8f6-6f2b-4211-b94c-4aaece20eb03"
      },
      "source": [
        "Setting image size and batch size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d367e0e7-c276-4bc4-bd14-07b166f660f0",
      "metadata": {
        "id": "d367e0e7-c276-4bc4-bd14-07b166f660f0"
      },
      "outputs": [],
      "source": [
        "\n",
        "IMG_SIZE = 224  # InceptionV3 expects 224x224 images\n",
        "BATCH_SIZE = 32\n",
        "SHUFFLE_BUFFER_SIZE = 1000"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "96baf3ca-8ae0-4687-b7f4-f8e23ed7f030",
      "metadata": {
        "id": "96baf3ca-8ae0-4687-b7f4-f8e23ed7f030"
      },
      "source": [
        "Helper function to load and preprocess images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "de432b27-1124-42b2-b3a2-83e31d96a5e1",
      "metadata": {
        "id": "de432b27-1124-42b2-b3a2-83e31d96a5e1"
      },
      "outputs": [],
      "source": [
        "# Function to load images from a folder and assign a label\n",
        "def load_images_from_folder(folder, label_value):\n",
        "    images = []\n",
        "    labels = []\n",
        "    for filename in os.listdir(folder):\n",
        "        img_path = os.path.join(folder, filename)\n",
        "        img = image.load_img(img_path, target_size=(IMG_SIZE, IMG_SIZE))\n",
        "        img_array = image.img_to_array(img)  # Rescale images to [0, 1]\n",
        "        # print(f\"==Loaded image shape==: {img_array.shape}\") #confirming if image is loaded\n",
        "        images.append(img_array)\n",
        "        labels.append(label_value)\n",
        "    return np.array(images), np.array(labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9677f31d-821e-4ebd-a02a-2b6d69e460bb",
      "metadata": {
        "id": "9677f31d-821e-4ebd-a02a-2b6d69e460bb"
      },
      "source": [
        "Load train and test datasets for all weather conditions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4e946c27-e7af-4fbb-aff0-aae06038be6a",
      "metadata": {
        "id": "4e946c27-e7af-4fbb-aff0-aae06038be6a"
      },
      "outputs": [],
      "source": [
        "train_images = []\n",
        "train_labels = []\n",
        "test_images = []\n",
        "test_labels = []\n",
        "\n",
        "for i, folder in enumerate(train_folders):\n",
        "    images, labels = load_images_from_folder(folder, i)  # Assign unique label i for each weather condition\n",
        "    train_images.append(images)\n",
        "    train_labels.append(labels)\n",
        "\n",
        "for i, folder in enumerate(test_folders):\n",
        "    images, labels = load_images_from_folder(folder, i)  # Same label for the test set\n",
        "    test_images.append(images)\n",
        "    test_labels.append(labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b5cb0804-3086-45ac-b059-6cefe394fe40",
      "metadata": {
        "id": "b5cb0804-3086-45ac-b059-6cefe394fe40"
      },
      "source": [
        "Combine the loaded images and labels for training and testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "77cbf205-7844-4da7-b0bb-ae9cd29334cf",
      "metadata": {
        "id": "77cbf205-7844-4da7-b0bb-ae9cd29334cf"
      },
      "outputs": [],
      "source": [
        "train_images = np.concatenate(train_images)\n",
        "train_labels = np.concatenate(train_labels)\n",
        "\n",
        "test_images = np.concatenate(test_images)\n",
        "test_labels = np.concatenate(test_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d80e77fa-a0b6-497d-a100-a44da1893ac4",
      "metadata": {
        "id": "d80e77fa-a0b6-497d-a100-a44da1893ac4"
      },
      "source": [
        "Define class names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2de01859-4604-4351-a127-6fbc660fe1c7",
      "metadata": {
        "id": "2de01859-4604-4351-a127-6fbc660fe1c7"
      },
      "outputs": [],
      "source": [
        "class_names = weather_conditions\n",
        "num_classes = len(class_names)\n",
        "\n",
        "print(f\"Loaded {len(train_images)} training images and {len(test_images)} test images.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5a6a654a-7f0c-4858-9e2b-f94b192e043f",
      "metadata": {
        "id": "5a6a654a-7f0c-4858-9e2b-f94b192e043f"
      },
      "source": [
        "### Format the Data\n",
        "Use the tf.image module to format the images for the task.\n",
        "Resize the images to a fixed input size, and rescale the input channels to a range of [-1,1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f91f9b2-b6cd-42ce-a2f6-0bc2f2ad8d56",
      "metadata": {
        "id": "0f91f9b2-b6cd-42ce-a2f6-0bc2f2ad8d56"
      },
      "outputs": [],
      "source": [
        "def format_example(image, label):\n",
        "    image = preprocess_input(image)  # Preprocess the image using InceptionV3 preprocessing\n",
        "    return image, label"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3ed23d3b-09c8-4424-a0cc-25d7076a9abd",
      "metadata": {
        "id": "3ed23d3b-09c8-4424-a0cc-25d7076a9abd"
      },
      "source": [
        "### Create TensorFlow datasets and apply the format function\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f3469d25-3e78-4b10-b14e-d85bc57cf85b",
      "metadata": {
        "id": "f3469d25-3e78-4b10-b14e-d85bc57cf85b"
      },
      "outputs": [],
      "source": [
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n",
        "train_dataset = train_dataset.map(format_example).shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE)\n",
        "\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((test_images, test_labels))\n",
        "test_dataset = test_dataset.map(format_example).batch(BATCH_SIZE)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7f06925d-a4e3-4f88-b7e6-dd3b72f12741",
      "metadata": {
        "id": "7f06925d-a4e3-4f88-b7e6-dd3b72f12741"
      },
      "source": [
        "### Inspect a batch of data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f049a4f6-a8dc-4a00-8cae-42a05bed56ce",
      "metadata": {
        "id": "f049a4f6-a8dc-4a00-8cae-42a05bed56ce"
      },
      "outputs": [],
      "source": [
        "\n",
        "for image_batch, label_batch in train_dataset.take(1):\n",
        "    print(f\"Image batch shape: {image_batch.shape}\")\n",
        "    print(f\"Label batch shape: {label_batch.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ca31215c-ce1a-4410-bbcf-995b69ad638a",
      "metadata": {
        "id": "ca31215c-ce1a-4410-bbcf-995b69ad638a"
      },
      "source": [
        "### Show the first Nine images and labels from the training set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc51a2d6-c9da-464e-8fa7-856ed3636159",
      "metadata": {
        "id": "fc51a2d6-c9da-464e-8fa7-856ed3636159"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12, 12))\n",
        "for i, (image, label) in enumerate(train_dataset.unbatch().take(9)):\n",
        "    plt.subplot(3, 3, i + 1)\n",
        "    image = image.numpy()\n",
        "    image = (image + 1.0) * 127.5\n",
        "    image = np.clip(image, 0, 255).astype(np.uint8)  # Ensure valid pixel values in range [0, 255]\n",
        "    plt.imshow(image)\n",
        "    plt.title(class_names[label.numpy()])\n",
        "    plt.axis(\"off\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5f4fa242-0f0a-4fb1-842c-3c526b90a980",
      "metadata": {
        "id": "5f4fa242-0f0a-4fb1-842c-3c526b90a980"
      },
      "outputs": [],
      "source": [
        "IMG_SHAPE = (IMG_SIZE, IMG_SIZE, 3)\n",
        "\n",
        "# Create the base model from the pre-trained InceptionV3\n",
        "\n",
        "base_model = tf.keras.applications.InceptionV3(input_shape=IMG_SHAPE,\n",
        "                                                  include_top=False,\n",
        "                                                  weights='imagenet',\n",
        "\n",
        "                                                 )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cd09439e-4998-4db6-81e2-44bf5b669558",
      "metadata": {
        "id": "cd09439e-4998-4db6-81e2-44bf5b669558"
      },
      "source": [
        "This feature extractor converts each `224x224x3` image into a `5x5x2048` block of features. See what it does to the example batch of images:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb38cab2-01a8-4e0b-b92d-0095fe9f84ad",
      "metadata": {
        "id": "cb38cab2-01a8-4e0b-b92d-0095fe9f84ad"
      },
      "outputs": [],
      "source": [
        "# Feature extractor output shape\n",
        "feature_batch = base_model(image_batch)\n",
        "print(f\"Feature batch shape: {feature_batch.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "be032949-9adf-4f14-a2e6-90f7f127189a",
      "metadata": {
        "id": "be032949-9adf-4f14-a2e6-90f7f127189a"
      },
      "outputs": [],
      "source": [
        "# Freeze the convolutional base\n",
        "base_model.trainable = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "affb4757-965a-4b90-8a79-4bef8d2e0ef8",
      "metadata": {
        "collapsed": true,
        "id": "affb4757-965a-4b90-8a79-4bef8d2e0ef8"
      },
      "outputs": [],
      "source": [
        "# Take a look at the base model architecture (InceptionV3)\n",
        "base_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "71365648-e793-4fa6-9a25-cf8b0d0b2521",
      "metadata": {
        "id": "71365648-e793-4fa6-9a25-cf8b0d0b2521"
      },
      "source": [
        "### Add a classification head"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "84267224-12de-446c-ada8-7ea3ba664842",
      "metadata": {
        "id": "84267224-12de-446c-ada8-7ea3ba664842"
      },
      "source": [
        "To generate predictions from the block of features, average over the spatial `5x5` spatial locations, using a `tf.keras.layers.GlobalAveragePooling2D` layer to convert the features to  a single 2048-element vector per image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed130e33-fd74-4f96-a674-f7c0599d22e6",
      "metadata": {
        "id": "ed130e33-fd74-4f96-a674-f7c0599d22e6"
      },
      "outputs": [],
      "source": [
        "# Use GlobalAveragePooling2D to convert the features to a single vector per image\n",
        "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
        "feature_batch_average = global_average_layer(feature_batch)\n",
        "print(f\"Feature batch after GlobalAveragePooling2D: {feature_batch_average.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9343322c-f6c2-4121-a2a9-1e42a8819458",
      "metadata": {
        "id": "9343322c-f6c2-4121-a2a9-1e42a8819458"
      },
      "source": [
        "Apply a `tf.keras.layers.Dense` layer to convert these features into a prediction per image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cfd3c18a-3fe7-49ec-859d-46fd14469d99",
      "metadata": {
        "id": "cfd3c18a-3fe7-49ec-859d-46fd14469d99"
      },
      "outputs": [],
      "source": [
        "# Add a Dense layer to convert features into predictions\n",
        "prediction_layer = tf.keras.layers.Dense(num_classes, activation='softmax')\n",
        "prediction_batch = prediction_layer(feature_batch_average)\n",
        "print(f\"Prediction batch shape: {prediction_batch.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "78580d40-b8a0-4ab9-856c-147d4802c23b",
      "metadata": {
        "id": "78580d40-b8a0-4ab9-856c-147d4802c23b"
      },
      "source": [
        "Now stack the feature extractor, and these two layers using a `tf.keras.Sequential` model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d61c03d0-c0cb-4b2c-bf9e-9a8a8b579834",
      "metadata": {
        "id": "d61c03d0-c0cb-4b2c-bf9e-9a8a8b579834"
      },
      "outputs": [],
      "source": [
        "# Stack the feature extractor and the classifier layers using Sequential model\n",
        "model = tf.keras.Sequential([\n",
        "    base_model,\n",
        "    global_average_layer,\n",
        "    prediction_layer\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f3064934-0bd3-432e-b032-2f1a639b816d",
      "metadata": {
        "id": "f3064934-0bd3-432e-b032-2f1a639b816d"
      },
      "source": [
        "### Compile the model\n",
        "\n",
        "You must compile the model before training it.  Since there are 102 classes, use a sparse categorical cross-entropy loss with `from_logits=True` since the model provides a linear output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "82e1630a-a1d9-4878-a29c-a15bd344d9cc",
      "metadata": {
        "id": "82e1630a-a1d9-4878-a29c-a15bd344d9cc"
      },
      "outputs": [],
      "source": [
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "05531184-5913-4abb-b818-7ff7ac729d33",
      "metadata": {
        "id": "05531184-5913-4abb-b818-7ff7ac729d33"
      },
      "outputs": [],
      "source": [
        "# Print the model summary\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## PERFORM TRANSFER LEARNING AND FINE TUNING HERE"
      ],
      "metadata": {
        "id": "5og1djiuPokI"
      },
      "id": "5og1djiuPokI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f924df68-4485-406f-8258-95f5886ea257",
      "metadata": {
        "id": "f924df68-4485-406f-8258-95f5886ea257"
      },
      "outputs": [],
      "source": [
        "### Evaluate the model on the test dataset\n",
        "### Without any transfer learning, InceptionV3 achieves\n",
        "### approximately 7.5% accuracy on the test dataset\n",
        "results = model.evaluate(test_dataset)\n",
        "print('Test loss, Test accuracy:', results)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}